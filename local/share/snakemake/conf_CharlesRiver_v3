import os
def find_prj_root(path=os.getcwd()):
	if os.path.isfile(os.path.join(path,".PRJ_ROOT")):
		return path
	else:
		if path:
			return find_prj_root(os.path.dirname(path))
		else:
			raise Exception("Can not find the PRJ_ROOT directory")


CORES=6
PRJ_ROOT=find_prj_root()
ROOT=os.getenv('SNAKE_ROOT')                                                    
BROOT=os.getenv('BIOINFO_ROOT')                                                    
DATA=PRJ_ROOT+"/local/share/data"
BIN_DIR=PRJ_ROOT+"/local/bin"
SRC_DIR=PRJ_ROOT+"/local/src"

BIT_DIR=BROOT+'/prj/ngs_standard_processing/dataset/CharlesRiver'

COUNTS_PRE_UNSTRANDED=BIT_DIR+"/unstranded/GEP.count.gz"
READS_UNSTRANDED=BIT_DIR+"/unstranded/usable_reads"
COUNTS_PRE_STRANDED=BIT_DIR+"/GEP.count.gz"
READS_STRANDED=BIT_DIR+"/usable_reads"
COUNTS="counts.tsv.gz"
GENE_LEN=BIT_DIR+"/gene_len"
PREMETA=BIT_DIR+'/ALL_infer_experiment'
META=DATA+"/metadata_charlesriver.tsv"
###
DESIGN="~stranded+Site.of.origin"
SPECIES="H" # if all do not filter, otherwise keep all genes that starts with 'SPECIES_'
SPECIES_ADD_DESC="" # org.Hs.eg.db is used by default, if needed set to -l org.Mm etc...
MINC=5
MINSAMPLES=2

#FILTERSAMPLES="yes" #  if yes keeps only samples in samples_data

GSEA_PATHWAYS=PRJ_ROOT+"/local/share/data/gsea/Hallmark_curated_hs_symbol.RData"
GSEA_PATHWAYS_NOTHALL=PRJ_ROOT+"/local/share/data/gsea/Not_hallmark_hs_entrez.RData"
GSEA=PRJ_ROOT+"/local/src/gsea.R"

rule ss:
    input: PREMETA
    output: 'meta.txt'
    shell:
        """
            echo -e "id\\tstranded" > {output}
            sed 1d {input} | bawk '$3 > 0.5 {{print $1,"firststrand"}} $3 <= 0.5 {{print $1,"unstranded"}}' >> {output}
            echo 'CHECK A MANO CHE THRESHOLD 0.5 sia SENSATO e VS LORO INFO'
        """

# fatto check a mano vs rnaseq_quality_control_information.tsv and the inference on strandness is correct.
# ho poi fatto girare a mano featureCounts stranded e unstranded in cartella di bit in maniera bieca, qui selezioniamo l'uno o l'altro dato.

# manual Rstudio session with different xls as sources (charles_river_metadata.R) results in samples_data.tsv in local/share/data

rule samples_data:
    input: meta=META
    output: "samples_data"
    shell:
        """
			cut -f 1,2,9,14 {input} | tr " " "_" > {output}
        """

# we need to get different counts for different samples cause life is bad and charles river dataset is an hybrid
rule counts:
    input: expr_matrix_ustr=COUNTS_PRE_UNSTRANDED, expr_matrix_str=COUNTS_PRE_STRANDED, meta="samples_data"
    output: expr_picked=COUNTS
    script: SRC_DIR+'/charlesriver_strandunstrand.R'


rule usable_reads:
    input: matrix_ustr=READS_UNSTRANDED, matrix_str=READS_STRANDED, meta="samples_data"
    output: picked= "usable_reads"
    script: SRC_DIR+'/charlesriver_strandunstrand_row.R'


#LFC=0.5849625 # 1.5 FC
#PVAL=0.05

#DEBUG="yes"
#MARKER=""
#MEDA_DIR=""
#SELECTED=""

rule n_reads:
    input: n_reads='usable_reads',counts='counts.tsv.gz'
    output: matrix='reads_info.tsv.gz'
    run:
        import pandas as pd
        counts = pd.read_csv(input.counts, sep="\t", index_col=0)
        # gather total mouse and human reads
        h_counts = counts.filter(regex="^H_", axis=0).sum(axis=0)
        m_counts = counts.filter(regex="^M_", axis=0).sum(axis=0)
        count_res = pd.DataFrame(data={'h_tot':h_counts, 'm_tot':m_counts, 'frac_h' : h_counts/(m_counts+h_counts)})
        usable_reads = pd.read_csv(input.n_reads, sep="\t", index_col=0, usecols=['sample', 'tot','Assigned'])
        usable_reads['frac_assigned'] = usable_reads['Assigned']/usable_reads['tot']
        res = pd.concat([count_res, usable_reads], axis=1, sort=True)
        res.to_csv(output.matrix, sep="\t", compression='gzip', header=True)